{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c5a44d",
   "metadata": {},
   "source": [
    "# Ridge & Lasso Regression Tutorial\n",
    "## Regularization: Taming Overfitting\n",
    "\n",
    "Welcome to **Regularized Regression** - where we add constraints to prevent overfitting!\n",
    "\n",
    "### What you'll learn:\n",
    "- Why regularization is needed\n",
    "- **Ridge Regression** (L2 regularization)\n",
    "- **Lasso Regression** (L1 regularization)\n",
    "- **Elastic Net** (L1 + L2 combined)\n",
    "- Feature selection with Lasso\n",
    "- Hyperparameter tuning with cross-validation\n",
    "- Regularization path visualization\n",
    "\n",
    "### Our Mission:\n",
    "Build **robust models** that generalize well by controlling complexity and selecting important features.\n",
    "\n",
    "Let's regularize! 🎯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f083e",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup\n",
    "\n",
    "Import specialized regularization tools and prepare our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "print(\"✅ Libraries imported and data loaded!\")\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa21c21",
   "metadata": {},
   "source": [
    "## Step 2: Create High-Dimensional Feature Space\n",
    "\n",
    "Generate many features (including polynomial) to demonstrate the need for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with high-dimensional features to show regularization benefits\n",
    "print(\"=\" * 50)\n",
    "print(\"HIGH-DIMENSIONAL FEATURE CREATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Handle categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "data_processed = data.copy()\n",
    "data_processed['location_encoded'] = label_encoder.fit_transform(data['location'])\n",
    "\n",
    "# Select base features\n",
    "base_features = ['area', 'bedrooms', 'age', 'location_encoded']\n",
    "X_base = data_processed[base_features]\n",
    "y = data_processed['price']\n",
    "\n",
    "print(f\"Base features: {base_features}\")\n",
    "print(f\"Base feature count: {X_base.shape[1]}\")\n",
    "\n",
    "# Create polynomial features (degree 3 for demonstration)\n",
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X_base)\n",
    "\n",
    "print(f\"Polynomial features count: {X_poly.shape[1]}\")\n",
    "print(f\"Feature expansion: {X_poly.shape[1] / X_base.shape[1]:.1f}x\")\n",
    "\n",
    "# Get feature names\n",
    "feature_names = poly_features.get_feature_names_out(base_features)\n",
    "print(f\"\\nFirst 10 polynomial features:\")\n",
    "for i, name in enumerate(feature_names[:10]):\n",
    "    print(f\"  {i+1:2d}. {name}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_poly, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features (essential for regularization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nData split and scaled:\")\n",
    "print(f\"Training samples: {X_train_scaled.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test_scaled.shape[0]}\")\n",
    "print(f\"Features: {X_train_scaled.shape[1]}\")\n",
    "print(\"✅ High-dimensional feature space created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f478221",
   "metadata": {},
   "source": [
    "## Step 3: Linear Regression Baseline (Overfitting Demo)\n",
    "\n",
    "First, let's see how regular linear regression performs with many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear regression on high-dimensional data\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_linear = linear_model.predict(X_train_scaled)\n",
    "y_test_pred_linear = linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "train_r2_linear = r2_score(y_train, y_train_pred_linear)\n",
    "test_r2_linear = r2_score(y_test, y_test_pred_linear)\n",
    "train_rmse_linear = np.sqrt(mean_squared_error(y_train, y_train_pred_linear))\n",
    "test_rmse_linear = np.sqrt(mean_squared_error(y_test, y_test_pred_linear))\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"LINEAR REGRESSION BASELINE (HIGH-DIMENSIONAL)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📊 Performance Metrics:\")\n",
    "print(f\"  Training R²:   {train_r2_linear:.4f}\")\n",
    "print(f\"  Testing R²:    {test_r2_linear:.4f}\")\n",
    "print(f\"  Training RMSE: ${train_rmse_linear:,.2f}\")\n",
    "print(f\"  Testing RMSE:  ${test_rmse_linear:,.2f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfitting_gap = train_r2_linear - test_r2_linear\n",
    "print(f\"\\n🔍 Overfitting Analysis:\")\n",
    "print(f\"  R² Gap (Train - Test): {overfitting_gap:.4f}\")\n",
    "\n",
    "if overfitting_gap > 0.1:\n",
    "    print(\"  ❌ Significant overfitting detected!\")\n",
    "    print(\"  💡 Regularization is needed.\")\n",
    "elif overfitting_gap > 0.05:\n",
    "    print(\"  ⚠️ Moderate overfitting detected.\")\n",
    "    print(\"  💡 Regularization would help.\")\n",
    "else:\n",
    "    print(\"  ✅ No significant overfitting.\")\n",
    "\n",
    "# Analyze coefficient distribution\n",
    "coefficients = linear_model.coef_\n",
    "print(f\"\\n📈 Coefficient Analysis:\")\n",
    "print(f\"  Number of features: {len(coefficients)}\")\n",
    "print(f\"  Coefficient range: [{coefficients.min():.2f}, {coefficients.max():.2f}]\")\n",
    "print(f\"  Coefficient std: {coefficients.std():.2f}\")\n",
    "print(f\"  Large coefficients (>10k): {sum(np.abs(coefficients) > 10000)}\")\n",
    "\n",
    "if coefficients.std() > 1000:\n",
    "    print(\"  ⚠️ High coefficient variance - model may be unstable\")\n",
    "\n",
    "print(\"\\n✅ Baseline established - ready for regularization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730b05f",
   "metadata": {},
   "source": [
    "## Step 4: Ridge Regression (L2 Regularization)\n",
    "\n",
    "Apply Ridge regression to shrink coefficients and reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore different Ridge alpha values\n",
    "ridge_alphas = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "ridge_results = []\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"RIDGE REGRESSION (L2 REGULARIZATION)\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Testing different regularization strengths...\\n\")\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    # Train Ridge model\n",
    "    ridge_model = Ridge(alpha=alpha, random_state=42)\n",
    "    ridge_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = ridge_model.predict(X_train_scaled)\n",
    "    y_test_pred = ridge_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    # Coefficient analysis\n",
    "    coef_norm = np.linalg.norm(ridge_model.coef_)\n",
    "    coef_std = ridge_model.coef_.std()\n",
    "    \n",
    "    ridge_results.append({\n",
    "        'alpha': alpha,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'coef_norm': coef_norm,\n",
    "        'coef_std': coef_std,\n",
    "        'overfitting_gap': train_r2 - test_r2,\n",
    "        'model': ridge_model\n",
    "    })\n",
    "    \n",
    "    print(f\"Alpha = {alpha:7.2f}: Test R² = {test_r2:.4f}, \"\n",
    "          f\"Gap = {train_r2 - test_r2:+.4f}, Coef Norm = {coef_norm:.1f}\")\n",
    "\n",
    "# Find best Ridge alpha\n",
    "best_ridge = max(ridge_results, key=lambda x: x['test_r2'])\n",
    "print(f\"\\n🎯 Best Ridge Alpha: {best_ridge['alpha']}\")\n",
    "print(f\"🎯 Best Test R²: {best_ridge['test_r2']:.4f}\")\n",
    "print(f\"🎯 Overfitting Gap: {best_ridge['overfitting_gap']:+.4f}\")\n",
    "\n",
    "# Cross-validation for more robust alpha selection\n",
    "ridge_cv = RidgeCV(alphas=ridge_alphas, cv=5, scoring='r2')\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n📊 Cross-Validation Results:\")\n",
    "print(f\"  Optimal Alpha (CV): {ridge_cv.alpha_}\")\n",
    "print(f\"  CV Score: {ridge_cv.score(X_test_scaled, y_test):.4f}\")\n",
    "\n",
    "# Compare with linear regression\n",
    "improvement = best_ridge['test_r2'] - test_r2_linear\n",
    "gap_reduction = overfitting_gap - best_ridge['overfitting_gap']\n",
    "\n",
    "print(f\"\\n💡 Ridge vs Linear Regression:\")\n",
    "print(f\"  R² improvement: {improvement:+.4f}\")\n",
    "print(f\"  Overfitting reduction: {gap_reduction:+.4f}\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"  ✅ Ridge regression improves generalization!\")\n",
    "else:\n",
    "    print(\"  ⚠️ Ridge regression doesn't improve this dataset.\")\n",
    "\n",
    "print(\"\\n✅ Ridge regression analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157a08f",
   "metadata": {},
   "source": [
    "## Step 5: Lasso Regression (L1 Regularization)\n",
    "\n",
    "Apply Lasso regression for automatic feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore different Lasso alpha values\n",
    "lasso_alphas = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "lasso_results = []\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"LASSO REGRESSION (L1 REGULARIZATION)\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Testing different regularization strengths...\\n\")\n",
    "\n",
    "for alpha in lasso_alphas:\n",
    "    # Train Lasso model\n",
    "    lasso_model = Lasso(alpha=alpha, random_state=42, max_iter=2000)\n",
    "    lasso_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = lasso_model.predict(X_train_scaled)\n",
    "    y_test_pred = lasso_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    # Feature selection analysis\n",
    "    selected_features = np.sum(lasso_model.coef_ != 0)\n",
    "    sparsity = 1 - (selected_features / len(lasso_model.coef_))\n",
    "    \n",
    "    lasso_results.append({\n",
    "        'alpha': alpha,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'selected_features': selected_features,\n",
    "        'sparsity': sparsity,\n",
    "        'overfitting_gap': train_r2 - test_r2,\n",
    "        'model': lasso_model\n",
    "    })\n",
    "    \n",
    "    print(f\"Alpha = {alpha:7.2f}: Test R² = {test_r2:.4f}, \"\n",
    "          f\"Features = {selected_features:3d}/{len(lasso_model.coef_)}, \"\n",
    "          f\"Sparsity = {sparsity:.1%}\")\n",
    "\n",
    "# Find best Lasso alpha\n",
    "best_lasso = max(lasso_results, key=lambda x: x['test_r2'])\n",
    "print(f\"\\n🎯 Best Lasso Alpha: {best_lasso['alpha']}\")\n",
    "print(f\"🎯 Best Test R²: {best_lasso['test_r2']:.4f}\")\n",
    "print(f\"🎯 Selected Features: {best_lasso['selected_features']}/{len(feature_names)}\")\n",
    "print(f\"🎯 Sparsity: {best_lasso['sparsity']:.1%}\")\n",
    "\n",
    "# Cross-validation for Lasso\n",
    "lasso_cv = LassoCV(alphas=lasso_alphas, cv=5, random_state=42, max_iter=2000)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\n📊 Cross-Validation Results:\")\n",
    "print(f\"  Optimal Alpha (CV): {lasso_cv.alpha_:.3f}\")\n",
    "print(f\"  CV Score: {lasso_cv.score(X_test_scaled, y_test):.4f}\")\n",
    "print(f\"  Selected Features (CV): {np.sum(lasso_cv.coef_ != 0)}\")\n",
    "\n",
    "# Feature selection analysis\n",
    "best_model = best_lasso['model']\n",
    "selected_indices = np.where(best_model.coef_ != 0)[0]\n",
    "selected_feature_names = [feature_names[i] for i in selected_indices]\n",
    "selected_coefficients = best_model.coef_[selected_indices]\n",
    "\n",
    "print(f\"\\n🔍 Selected Features (Top 10):\")\n",
    "feature_importance = list(zip(selected_feature_names, np.abs(selected_coefficients)))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (feature, coef) in enumerate(feature_importance[:10], 1):\n",
    "    print(f\"  {i:2d}. {feature:25s}: {coef:8.2f}\")\n",
    "\n",
    "print(\"\\n✅ Lasso regression analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcc2a9",
   "metadata": {},
   "source": [
    "## Step 6: Elastic Net (L1 + L2 Regularization)\n",
    "\n",
    "Combine the benefits of both Ridge and Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net with grid search for best parameters\n",
    "print(\"=\" * 50)\n",
    "print(\"ELASTIC NET REGRESSION (L1 + L2)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # 0 = Ridge, 1 = Lasso\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "elastic_net = ElasticNet(random_state=42, max_iter=2000)\n",
    "grid_search = GridSearchCV(\n",
    "    elastic_net, param_grid, cv=5, scoring='r2', n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_elastic = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"🔍 Grid Search Results:\")\n",
    "print(f\"  Best Alpha: {best_params['alpha']}\")\n",
    "print(f\"  Best L1 Ratio: {best_params['l1_ratio']}\")\n",
    "print(f\"  Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Interpret L1 ratio\n",
    "l1_ratio = best_params['l1_ratio']\n",
    "if l1_ratio < 0.3:\n",
    "    regularization_type = \"Mostly Ridge (L2)\"\n",
    "elif l1_ratio > 0.7:\n",
    "    regularization_type = \"Mostly Lasso (L1)\"\n",
    "else:\n",
    "    regularization_type = \"Balanced (L1 + L2)\"\n",
    "\n",
    "print(f\"  Regularization Type: {regularization_type}\")\n",
    "\n",
    "# Evaluate best Elastic Net\n",
    "y_train_pred_elastic = best_elastic.predict(X_train_scaled)\n",
    "y_test_pred_elastic = best_elastic.predict(X_test_scaled)\n",
    "\n",
    "train_r2_elastic = r2_score(y_train, y_train_pred_elastic)\n",
    "test_r2_elastic = r2_score(y_test, y_test_pred_elastic)\n",
    "train_rmse_elastic = np.sqrt(mean_squared_error(y_train, y_train_pred_elastic))\n",
    "test_rmse_elastic = np.sqrt(mean_squared_error(y_test, y_test_pred_elastic))\n",
    "\n",
    "# Feature selection\n",
    "selected_features_elastic = np.sum(best_elastic.coef_ != 0)\n",
    "sparsity_elastic = 1 - (selected_features_elastic / len(best_elastic.coef_))\n",
    "\n",
    "print(f\"\\n📊 Best Elastic Net Performance:\")\n",
    "print(f\"  Training R²: {train_r2_elastic:.4f}\")\n",
    "print(f\"  Testing R²: {test_r2_elastic:.4f}\")\n",
    "print(f\"  Training RMSE: ${train_rmse_elastic:,.2f}\")\n",
    "print(f\"  Testing RMSE: ${test_rmse_elastic:,.2f}\")\n",
    "print(f\"  Selected Features: {selected_features_elastic}/{len(feature_names)}\")\n",
    "print(f\"  Sparsity: {sparsity_elastic:.1%}\")\n",
    "print(f\"  Overfitting Gap: {train_r2_elastic - test_r2_elastic:+.4f}\")\n",
    "\n",
    "# Store results for comparison\n",
    "elastic_results = {\n",
    "    'train_r2': train_r2_elastic,\n",
    "    'test_r2': test_r2_elastic,\n",
    "    'train_rmse': train_rmse_elastic,\n",
    "    'test_rmse': test_rmse_elastic,\n",
    "    'selected_features': selected_features_elastic,\n",
    "    'sparsity': sparsity_elastic,\n",
    "    'overfitting_gap': train_r2_elastic - test_r2_elastic\n",
    "}\n",
    "\n",
    "print(\"\\n✅ Elastic Net analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737eccfe",
   "metadata": {},
   "source": [
    "## Step 7: Comprehensive Model Comparison\n",
    "\n",
    "Compare all regularization methods and analyze their trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed745f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison of all models\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Collect all results\n",
    "models_comparison = {\n",
    "    'Linear Regression': {\n",
    "        'train_r2': train_r2_linear,\n",
    "        'test_r2': test_r2_linear,\n",
    "        'train_rmse': train_rmse_linear,\n",
    "        'test_rmse': test_rmse_linear,\n",
    "        'selected_features': len(feature_names),\n",
    "        'sparsity': 0.0,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'regularization': 'None'\n",
    "    },\n",
    "    'Ridge (Best)': {\n",
    "        'train_r2': best_ridge['train_r2'],\n",
    "        'test_r2': best_ridge['test_r2'],\n",
    "        'train_rmse': best_ridge['train_rmse'],\n",
    "        'test_rmse': best_ridge['test_rmse'],\n",
    "        'selected_features': len(feature_names),\n",
    "        'sparsity': 0.0,\n",
    "        'overfitting_gap': best_ridge['overfitting_gap'],\n",
    "        'regularization': f\"L2 (α={best_ridge['alpha']})\"\n",
    "    },\n",
    "    'Lasso (Best)': {\n",
    "        'train_r2': best_lasso['train_r2'],\n",
    "        'test_r2': best_lasso['test_r2'],\n",
    "        'train_rmse': best_lasso['train_rmse'],\n",
    "        'test_rmse': best_lasso['test_rmse'],\n",
    "        'selected_features': best_lasso['selected_features'],\n",
    "        'sparsity': best_lasso['sparsity'],\n",
    "        'overfitting_gap': best_lasso['overfitting_gap'],\n",
    "        'regularization': f\"L1 (α={best_lasso['alpha']})\"\n",
    "    },\n",
    "    'Elastic Net': {\n",
    "        'train_r2': elastic_results['train_r2'],\n",
    "        'test_r2': elastic_results['test_r2'],\n",
    "        'train_rmse': elastic_results['train_rmse'],\n",
    "        'test_rmse': elastic_results['test_rmse'],\n",
    "        'selected_features': elastic_results['selected_features'],\n",
    "        'sparsity': elastic_results['sparsity'],\n",
    "        'overfitting_gap': elastic_results['overfitting_gap'],\n",
    "        'regularization': f\"L1+L2 (α={best_params['alpha']}, ratio={best_params['l1_ratio']})\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "print(f\"{'Model':15s} {'Test R²':>10s} {'RMSE':>12s} {'Features':>10s} {'Sparsity':>10s} {'Gap':>8s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model_name, results in models_comparison.items():\n",
    "    print(f\"{model_name:15s} {results['test_r2']:10.4f} \"\n",
    "          f\"${results['test_rmse']:10,.0f} {results['selected_features']:8d} \"\n",
    "          f\"{results['sparsity']:9.1%} {results['overfitting_gap']:+7.3f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(models_comparison.keys(), \n",
    "                      key=lambda x: models_comparison[x]['test_r2'])\n",
    "best_model_results = models_comparison[best_model_name]\n",
    "\n",
    "print(f\"\\n🏆 BEST MODEL: {best_model_name}\")\n",
    "print(f\"  Test R²: {best_model_results['test_r2']:.4f}\")\n",
    "print(f\"  RMSE: ${best_model_results['test_rmse']:,.2f}\")\n",
    "print(f\"  Features: {best_model_results['selected_features']}/{len(feature_names)}\")\n",
    "print(f\"  Regularization: {best_model_results['regularization']}\")\n",
    "\n",
    "# Analysis insights\n",
    "print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "\n",
    "# Overfitting analysis\n",
    "linear_gap = models_comparison['Linear Regression']['overfitting_gap']\n",
    "regularized_gaps = [results['overfitting_gap'] for name, results in models_comparison.items() \n",
    "                   if name != 'Linear Regression']\n",
    "avg_regularized_gap = np.mean(regularized_gaps)\n",
    "\n",
    "print(f\"  • Regularization reduced overfitting by {linear_gap - avg_regularized_gap:.3f} on average\")\n",
    "\n",
    "# Feature selection\n",
    "lasso_features = models_comparison['Lasso (Best)']['selected_features']\n",
    "total_features = len(feature_names)\n",
    "feature_reduction = (total_features - lasso_features) / total_features\n",
    "\n",
    "print(f\"  • Lasso eliminated {feature_reduction:.1%} of features while maintaining performance\")\n",
    "\n",
    "# Performance comparison\n",
    "linear_r2 = models_comparison['Linear Regression']['test_r2']\n",
    "best_r2 = best_model_results['test_r2']\n",
    "improvement = best_r2 - linear_r2\n",
    "\n",
    "if improvement > 0.01:\n",
    "    print(f\"  • Regularization improved test performance by {improvement:.3f} R²\")\n",
    "elif improvement > 0:\n",
    "    print(f\"  • Regularization slightly improved generalization\")\n",
    "else:\n",
    "    print(f\"  • Regularization didn't improve performance (data may not need it)\")\n",
    "\n",
    "print(\"\\n✅ Comprehensive comparison complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c91a2",
   "metadata": {},
   "source": [
    "## Step 8: Regularization Path Visualization\n",
    "\n",
    "Visualize how regularization affects coefficients and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Regularization Analysis and Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Ridge Regularization Path\n",
    "ridge_alphas_plot = [result['alpha'] for result in ridge_results]\n",
    "ridge_test_r2s = [result['test_r2'] for result in ridge_results]\n",
    "ridge_gaps = [result['overfitting_gap'] for result in ridge_results]\n",
    "\n",
    "axes[0, 0].semilogx(ridge_alphas_plot, ridge_test_r2s, 'o-', color='blue', label='Test R²')\n",
    "axes[0, 0].axhline(y=test_r2_linear, color='red', linestyle='--', label='Linear Baseline')\n",
    "axes[0, 0].axvline(x=best_ridge['alpha'], color='green', linestyle=':', label='Best α')\n",
    "axes[0, 0].set_xlabel('Ridge Alpha (Log Scale)')\n",
    "axes[0, 0].set_ylabel('Test R²')\n",
    "axes[0, 0].set_title('Ridge Regularization Path')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Lasso Regularization Path\n",
    "lasso_alphas_plot = [result['alpha'] for result in lasso_results]\n",
    "lasso_test_r2s = [result['test_r2'] for result in lasso_results]\n",
    "lasso_features = [result['selected_features'] for result in lasso_results]\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "ax2_twin = ax2.twinx()\n",
    "\n",
    "line1 = ax2.semilogx(lasso_alphas_plot, lasso_test_r2s, 'o-', color='blue', label='Test R²')\n",
    "line2 = ax2_twin.semilogx(lasso_alphas_plot, lasso_features, 's-', color='red', label='# Features')\n",
    "ax2.axhline(y=test_r2_linear, color='gray', linestyle='--', alpha=0.7)\n",
    "ax2.axvline(x=best_lasso['alpha'], color='green', linestyle=':', label='Best α')\n",
    "\n",
    "ax2.set_xlabel('Lasso Alpha (Log Scale)')\n",
    "ax2.set_ylabel('Test R²', color='blue')\n",
    "ax2_twin.set_ylabel('Selected Features', color='red')\n",
    "ax2.set_title('Lasso Feature Selection Path')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Combine legends\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax2.legend(lines, labels, loc='center right')\n",
    "\n",
    "# 3. Overfitting Comparison\n",
    "model_names = list(models_comparison.keys())\n",
    "overfitting_gaps = [models_comparison[name]['overfitting_gap'] for name in model_names]\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "bars = axes[0, 2].bar(range(len(model_names)), overfitting_gaps, \n",
    "                      color=colors, alpha=0.7)\n",
    "axes[0, 2].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[0, 2].set_xlabel('Model')\n",
    "axes[0, 2].set_ylabel('Overfitting Gap (Train R² - Test R²)')\n",
    "axes[0, 2].set_title('Overfitting Comparison')\n",
    "axes[0, 2].set_xticks(range(len(model_names)))\n",
    "axes[0, 2].set_xticklabels([name.split()[0] for name in model_names], rotation=45)\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, gap in zip(bars, overfitting_gaps):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                    f'{gap:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 4. Coefficient Magnitude Comparison\n",
    "# Compare coefficient norms for different regularization strengths\n",
    "ridge_coef_norms = [result['coef_norm'] for result in ridge_results]\n",
    "axes[1, 0].semilogx(ridge_alphas_plot, ridge_coef_norms, 'o-', color='blue')\n",
    "axes[1, 0].axhline(y=np.linalg.norm(linear_model.coef_), color='red', \n",
    "                   linestyle='--', label='Linear Baseline')\n",
    "axes[1, 0].set_xlabel('Ridge Alpha (Log Scale)')\n",
    "axes[1, 0].set_ylabel('Coefficient L2 Norm')\n",
    "axes[1, 0].set_title('Ridge Coefficient Shrinkage')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Feature Selection Visualization\n",
    "sparsity_levels = [result['sparsity'] for result in lasso_results]\n",
    "axes[1, 1].semilogx(lasso_alphas_plot, sparsity_levels, 'o-', color='green')\n",
    "axes[1, 1].set_xlabel('Lasso Alpha (Log Scale)')\n",
    "axes[1, 1].set_ylabel('Sparsity (% Features Eliminated)')\n",
    "axes[1, 1].set_title('Lasso Sparsity Path')\n",
    "axes[1, 1].axvline(x=best_lasso['alpha'], color='red', linestyle=':', label='Best α')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Performance vs Complexity Trade-off\n",
    "all_test_r2s = [models_comparison[name]['test_r2'] for name in model_names]\n",
    "all_features = [models_comparison[name]['selected_features'] for name in model_names]\n",
    "\n",
    "scatter = axes[1, 2].scatter(all_features, all_test_r2s, s=100, c=colors, alpha=0.7)\n",
    "for i, name in enumerate(model_names):\n",
    "    axes[1, 2].annotate(name.split()[0], (all_features[i], all_test_r2s[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "axes[1, 2].set_xlabel('Number of Selected Features')\n",
    "axes[1, 2].set_ylabel('Test R²')\n",
    "axes[1, 2].set_title('Performance vs Model Complexity')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Regularization visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00768dc1",
   "metadata": {},
   "source": [
    "## Step 9: Summary and Key Insights\n",
    "\n",
    "### 🎯 What We Accomplished:\n",
    "1. **Demonstrated overfitting** with high-dimensional linear regression\n",
    "2. **Applied Ridge regression** (L2) to shrink coefficients\n",
    "3. **Used Lasso regression** (L1) for automatic feature selection\n",
    "4. **Combined both** with Elastic Net regularization\n",
    "5. **Optimized hyperparameters** using cross-validation\n",
    "6. **Visualized regularization paths** and trade-offs\n",
    "7. **Compared all methods** comprehensively\n",
    "\n",
    "### 📊 Key Results:\n",
    "- **Best Model**: {best_model_name}\n",
    "- **Test R²**: {best_model_results['test_r2']:.4f}\n",
    "- **Feature Reduction**: {(len(feature_names) - best_model_results['selected_features'])/len(feature_names):.1%}\n",
    "- **Overfitting Reduction**: {linear_gap - best_model_results['overfitting_gap']:+.3f}\n",
    "\n",
    "### 💡 Key Learnings:\n",
    "\n",
    "**Ridge Regression (L2):**\n",
    "- **Shrinks coefficients** towards zero but doesn't eliminate them\n",
    "- **Reduces overfitting** by penalizing large coefficients\n",
    "- **Works well** when many features are relevant\n",
    "- **Computationally efficient** and numerically stable\n",
    "\n",
    "**Lasso Regression (L1):**\n",
    "- **Eliminates irrelevant features** by setting coefficients to zero\n",
    "- **Performs automatic feature selection**\n",
    "- **Creates sparse models** that are interpretable\n",
    "- **Can struggle** when features are highly correlated\n",
    "\n",
    "**Elastic Net:**\n",
    "- **Combines benefits** of Ridge and Lasso\n",
    "- **Handles correlated features** better than Lasso alone\n",
    "- **Provides balanced regularization**\n",
    "- **Requires tuning** two hyperparameters\n",
    "\n",
    "**When to Use Each:**\n",
    "- **Ridge**: Many relevant features, multicollinearity\n",
    "- **Lasso**: Feature selection needed, sparse solutions desired\n",
    "- **Elastic Net**: Mixed requirements, correlated features\n",
    "\n",
    "### ⚖️ The Bias-Variance-Sparsity Tradeoff:\n",
    "- **No Regularization**: Low bias, high variance, all features\n",
    "- **Ridge**: Slight bias increase, variance reduction, all features\n",
    "- **Lasso**: Moderate bias, variance reduction, feature selection\n",
    "- **High Regularization**: High bias, low variance, few features\n",
    "\n",
    "### 🔧 Practical Guidelines:\n",
    "1. **Always scale features** before regularization\n",
    "2. **Use cross-validation** to select hyperparameters\n",
    "3. **Start with Elastic Net** for unknown problems\n",
    "4. **Plot regularization paths** to understand behavior\n",
    "5. **Consider domain knowledge** in feature selection\n",
    "\n",
    "### 🚀 Next Steps:\n",
    "- Explore **advanced regularization** (Group Lasso, Sparse Group Lasso)\n",
    "- Learn about **kernel methods** and **support vector machines**\n",
    "- Study **ensemble methods** (Random Forest, Gradient Boosting)\n",
    "- Practice with **time series** and **multi-output** regression\n",
    "\n",
    "### 🤔 Questions to Explore:\n",
    "- How do we choose between L1 and L2 regularization?\n",
    "- What happens when we have more features than samples?\n",
    "- How does regularization relate to Bayesian methods?\n",
    "- Can we combine regularization with other techniques?\n",
    "\n",
    "Excellent work mastering regularization techniques! 🎉\n",
    "\n",
    "You now understand how to:\n",
    "- **Control overfitting** with smart constraints\n",
    "- **Select important features** automatically\n",
    "- **Balance model complexity** and performance\n",
    "- **Build robust models** that generalize well\n",
    "\n",
    "These skills are fundamental for real-world machine learning success! 🌟"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
